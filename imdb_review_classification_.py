# -*- coding: utf-8 -*-
"""IMDB review classification .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15OsuZxzRxab6IiFAO2jk6uWeC5ssM3xG

# step 1 : installation and set up
"""

pip install tensorflow-gpu

import tensorflow as tf

print (tf.__version__)

import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt

"""# step : 2 Data Preprocessing"""

# importing the libraries 
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences

# load the dataset
(x_train ,y_train), (x_test, y_test) = imdb.load_data(num_words=20000)

x_train

# aqpply padding to fixed the length 
x_train = pad_sequences(x_train, maxlen=100)
x_test = pad_sequences(x_test, maxlen=100)

x_train.shape,x_test.shape

"""# step 3 : building the model"""

# define the object (initializing the RNN )
model = tf.keras.models.Sequential()

# Embedding layer 
model.add(tf.keras.layers.Embedding(input_dim=20000,output_dim=128,input_shape=(100,)))

# LSTM layer 
model.add(tf.keras.layers.LSTM(units=128,activation='tanh'))

#output layers 
model.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))

model.summary()

# compile the model 
model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])

"""# step 4 : training the model"""

history = model.fit(x_train,y_train,batch_size=128,epochs=5,validation_data=(x_test,y_test))

# predictions 
y_pred =model.predict_classes(x_test)

print(y_pred[10]), print(y_test[10])

# confusion matrix
from sklearn.metrics import confusion_matrix,accuracy_score
cm = confusion_matrix(y_test,y_pred)
print (cm)

acc_cm = accuracy_score(y_test,y_pred)
print(acc_cm)

"""# step 5 : Learning curve"""

def learning_curve (history,epoch):
  # training vs validation accuracy
  epoch_range = range (1,epoch+1)
  plt.plot(epoch_range, history.history['accuracy'])
  plt.plot(epoch_range, history.history['val_accuracy'])
  plt.title('model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train','val'], loc ='upper left')
  plt.show()


  #training vs validation loss
  plt.plot(epoch_range, history.history['loss'])
  plt.plot(epoch_range, history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('Epoch')
  plt.legend(['Train','val'], loc ='upper left')
  plt.show()

learning_curve(history , 5)